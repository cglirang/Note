## 训练句子表示的两种研究方法

### 监督学习
+ 大量有标签数据训练，在多种任务中有成功的应用
+ 图片分类任务训练出了分层的特征探测器
+ 计算机视觉中易于迁移学习


### 非监督学习
+ 训练规模大于特定领域，数据没有标注不够clean、privacy或其他限制条件，是优点也是难点
+ 相比监督学习（优化目标清晰），依赖一些代理任务（语言模型）顺便得到
+ 一些工作尝试加入了设计目标、先验经验、框架
+ 应用：pre-train（词共现）、Topic modelling
+ 一种具体训练方法 skip-thought vector（大数据量，一个句子预测先后出现的句子），在分类（能否encode出明显特征）等任务上的效果还是不如监督的训练方法，尤其在数据量较小的情况下
+ 在特定数据集下，非监督pre-train + 监督微调的效果比随机初始化的模型效果更好


## 纯非监督训练效果不好的假设
+ 训练数据和测试数据没有重叠：Skip-thought Vector用小说数据训练，测试数据是商品评价
+ 模型能力有限
+ 当前的分布式句子表示损失很大，虽然善于捕捉要点，但精确语义或句法细节很难捕捉到
+ 非监督的表示学习被低估了


## 文章目标
+ 专注于语义分析，训练一个非监督文档表示来准确表示语义
+ 训练字符级别（byte level）语言模型，因为简单性和普遍性
+ 测试低级别的目标是否可以支持高等级的句子表示任务
+ 用非常大的数据集训练
+ 对更广泛的任务进行测试


## 数据集
+ 训练集：Amazon product review dataset introduced in McAuley et al. (2015)，去重后是从1996年5月至2014年7月的8200万的产品评价，380亿个字节，
+ 分为1000份，1份用来验证1份用来测试


## 模型和训练细节
+ 数据量太大，需要先评估较小候选模型的生成性能
+ 选用的大规模数据量训练的模型是单层乘积LSTM（mLSTM）with 4096 units，因为mLSTM比普通LSTM在数据和时间上都收敛更快
+ single epoch on mini-batches of 128 subsequences of length 256 of 1 million weight updates
+ 每份数据开始训练states初始化为0
+ Adam optimizer
+ initial 5e-4 learning rate 
+ Weight normalization
+ 4块Pascal Titan X gpus并行训练一个月


## 实验设置
+ 非监督：每个字符预测下一个字符出现的概率
+ 监督：语义相似度、文本分类


## 情感分析
+ 四种情感分析数据集测试，MR和CR达到state of the art，因为与非监督的训练语料有重叠，证明模型在这个domain中学习到了语义更丰富的表示，而在另外两个数据集上的表现依然不如监督学习
+ 验证情感分析，在SST数据集（数据量小 复杂）二分类任务上达到91.8%超过state of the art 90.2%，并且数据利用率非常高，但是在多分类任务上没有达到最高


## 情感神经元
+ 研究为什么这个模型会有好的效果和数据利用率高，线索是L1正则（降低样本复杂度）在low data regime（数据量小?）的情况下效果更好，可能是因为模型是被训练为语言模型而不是特征提取器，通过检查各种数据集上特征的相对贡献，找到了直接控制情感的single unit
+ 仅用single unit做特征，在IMDB测试超过了监督学习，不如半监督，使用4096 units做特征提升很少，证明情感都包含在单个的情感神经元里


## 性能上限
+ 短文本小数据集领域相似会有好结果，文档级的大数据集上领域不重叠表现不好


## 文本生成
+ 改变情感神经元的值就可以控制生成出的句子的情感

## 结论
+ 情感作为条件特征具有较强的语言建模预测能力
+ 标准的语言建模目标可以学习到高质量的文档表示